#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LeRobot æ•°æ®é›†å¯è§†åŒ–ç‹¬ç«‹è„šæœ¬

è¿™ä¸ªè„šæœ¬æä¾›äº†ä¸ lerobot-dataset-viz ç›¸åŒçš„åŠŸèƒ½ï¼Œä½†å¯ä»¥ç‹¬ç«‹è¿è¡Œã€‚

åŠŸèƒ½è¯´æ˜ï¼š
    å¯è§†åŒ– LeRobotDataset ç±»å‹æ•°æ®é›†ä¸­ä»»æ„æƒ…èŠ‚çš„æ‰€æœ‰å¸§æ•°æ®ã€‚
    æ”¯æŒå›¾åƒã€åŠ¨ä½œã€çŠ¶æ€ã€å¥–åŠ±ç­‰å¤šç§æ•°æ®ç±»å‹çš„å¯è§†åŒ–ã€‚

ä¾èµ–ï¼š
    pip install rerun torch numpy tqdm
    pip install lerobot  # éœ€è¦å®‰è£… lerobot åŒ…

ä½¿ç”¨ç¤ºä¾‹ï¼š

1. æœ¬åœ°å¯è§†åŒ–æ•°æ®é›†ï¼š
   python standalone_dataset_viz.py \
       --repo-id lerobot/pusht \
       --episode-index 0

2. ä¿å­˜ä¸º .rrd æ–‡ä»¶ï¼ˆç”¨äºæœ¬åœ°æŸ¥çœ‹ï¼‰ï¼š
   python standalone_dataset_viz.py \
       --repo-id lerobot/pusht \
       --episode-index 0 \
       --save 1 \
       --output-dir ./output

   ç„¶ååœ¨æœ¬åœ°æŸ¥çœ‹ï¼š
   rerun ./output/lerobot_pusht_episode_0.rrd

3. è¿œç¨‹æœºå™¨ä¸Šé€šè¿‡æµå¼ä¼ è¾“æŸ¥çœ‹ï¼š
   ï¼ˆéœ€è¦è½¬å‘ websocket ç«¯å£åˆ°è¿œç¨‹æœºå™¨ï¼‰
   ssh -L 9087:localhost:9087 username@remote-host

   åœ¨è¿œç¨‹æœºå™¨ä¸Šè¿è¡Œï¼š
   python standalone_dataset_viz.py \
       --repo-id lerobot/pusht \
       --episode-index 0 \
       --mode distant \
       --ws-port 9087

   åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œï¼š
   rerun ws://localhost:9087

4. ä½¿ç”¨æœ¬åœ°æ•°æ®é›†ï¼ˆæ¨èï¼‰ï¼š
   python standalone_dataset_viz.py \
       --repo-id so101_v3_dataset1_clean \
       --episode-index 0 \
       --root D: \
       --local

python standalone_dataset_viz.py --repo-id D:\so101_v3_dataset1_clean --episode-index 0 --root  "D:\so101_v3_dataset1_clean" --local

   å½“ä½¿ç”¨ --local å‚æ•°æ—¶ï¼Œè„šæœ¬ä¸ä¼šå°è¯•è¿æ¥ HuggingFaceï¼Œ
   ç›´æ¥ä»æœ¬åœ°åŠ è½½æ•°æ®é›†ã€‚é€‚ç”¨äºè‡ªå®šä¹‰/æœ¬åœ°é‡‡é›†çš„æ•°æ®é›†ã€‚

å‚æ•°è¯´æ˜ï¼š
    --repo-id: æ•°æ®é›†åç§°æˆ– HuggingFace ä»“åº“ IDï¼ˆä¾‹å¦‚ï¼šlerobot/pushtï¼‰
    --episode-index: è¦å¯è§†åŒ–çš„æƒ…èŠ‚ç´¢å¼•
    --root: æœ¬åœ°æ•°æ®é›†æ ¹ç›®å½•ï¼ˆä½¿ç”¨ --local æ—¶å¿…éœ€ï¼‰
    --output-dir: è¾“å‡º .rrd æ–‡ä»¶çš„ç›®å½•
    --batch-size: DataLoader çš„æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼š32ï¼‰
    --num-workers: æ•°æ®åŠ è½½çš„å·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š4ï¼‰
    --mode: æŸ¥çœ‹æ¨¡å¼ï¼Œ'local' æˆ– 'distant'ï¼ˆé»˜è®¤ï¼šlocalï¼‰
    --web-port: rerun çš„ Web ç«¯å£ï¼ˆé»˜è®¤ï¼š9090ï¼‰
    --ws-port: rerun çš„ WebSocket ç«¯å£ï¼ˆé»˜è®¤ï¼š9087ï¼‰
    --save: æ˜¯å¦ä¿å­˜ä¸º .rrd æ–‡ä»¶ï¼ˆ0 æˆ– 1ï¼Œé»˜è®¤ï¼š0ï¼‰
    --tolerance-s: æ—¶é—´æˆ³å®¹å·®ï¼ˆç§’ï¼Œé»˜è®¤ï¼š1e-4ï¼‰
"""

import argparse
import gc
import logging
import sys
import time
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies():
    """æ£€æŸ¥æ‰€éœ€çš„ä¾èµ–åŒ…æ˜¯å¦å·²å®‰è£…"""
    missing_deps = []

    try:
        import numpy
    except ImportError:
        missing_deps.append("numpy")

    try:
        import torch
    except ImportError:
        missing_deps.append("torch")

    try:
        import rerun
    except ImportError:
        missing_deps.append("rerun")

    try:
        import tqdm
    except ImportError:
        missing_deps.append("tqdm")

    try:
        import lerobot
    except ImportError:
        missing_deps.append("lerobot")

    if missing_deps:
        logger.error("ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for dep in missing_deps:
            logger.error(f"  - {dep}")
        logger.error("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
        if "lerobot" in missing_deps:
            logger.error("  pip install lerobot")
        logger.error("  pip install rerun torch numpy tqdm")
        sys.exit(1)

    logger.info("æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡ âœ“")


def to_hwc_uint8_numpy(chw_float32_torch):
    """
    å°† CHW æ ¼å¼çš„ float32 torch tensor è½¬æ¢ä¸º HWC æ ¼å¼çš„ uint8 numpy array

    å‚æ•°:
        chw_float32_torch: å½¢çŠ¶ä¸º (C, H, W) çš„ torch.Tensorï¼Œå€¼èŒƒå›´ [0, 1]

    è¿”å›:
        hwc_uint8_numpy: å½¢çŠ¶ä¸º (H, W, C) çš„ numpy arrayï¼Œå€¼èŒƒå›´ [0, 255]
    """
    import torch
    import numpy as np

    assert chw_float32_torch.dtype == torch.float32, f"æœŸæœ› float32ï¼Œå¾—åˆ° {chw_float32_torch.dtype}"
    assert chw_float32_torch.ndim == 3, f"æœŸæœ› 3 ç»´ï¼Œå¾—åˆ° {chw_float32_torch.ndim}"
    c, h, w = chw_float32_torch.shape
    assert c < h and c < w, f"æœŸæœ›é€šé“åœ¨å‰çš„å›¾åƒæ ¼å¼ï¼Œä½†å¾—åˆ° {chw_float32_torch.shape}"
    hwc_uint8_numpy = (chw_float32_torch * 255).type(torch.uint8).permute(1, 2, 0).numpy()
    return hwc_uint8_numpy


def visualize_dataset(
    dataset,
    repo_id: str,
    episode_index: int,
    batch_size: int = 32,
    num_workers: int = 0,
    mode: str = "local",
    web_port: int = 9090,
    ws_port: int = 9087,
    save: bool = False,
    output_dir: Path | None = None,
    jpeg_quality: int = 85,
    scale_factor: float | None = None,
):
    """
    å¯è§†åŒ–æ•°æ®é›†

    å‚æ•°:
        dataset: LeRobotDataset å®ä¾‹
        repo_id: æ•°æ®é›†åç§°
        episode_index: è¦å¯è§†åŒ–çš„æƒ…èŠ‚ç´¢å¼•
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•°æ®åŠ è½½çš„å·¥ä½œè¿›ç¨‹æ•°
        mode: 'local' æˆ– 'distant'
        web_port: Web ç«¯å£ï¼ˆdistant æ¨¡å¼ï¼‰
        ws_port: WebSocket ç«¯å£ï¼ˆdistant æ¨¡å¼ï¼‰
        save: æ˜¯å¦ä¿å­˜ä¸º .rrd æ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•
        jpeg_quality: JPEG å‹ç¼©è´¨é‡ (1-100, é»˜è®¤85ï¼Œè¶Šä½æ–‡ä»¶è¶Šå°)
        scale_factor: å›¾åƒç¼©æ”¾å› å­ (é»˜è®¤1.0=åŸå°ºå¯¸, 0.5=åŠå°ºå¯¸)

    è¿”å›:
        å¦‚æœ save=Trueï¼Œè¿”å› .rrd æ–‡ä»¶è·¯å¾„
    """
    import torch
    import tqdm
    import rerun as rr

    if save:
        assert output_dir is not None, (
            "è¯·ä½¿ç”¨ --output-dir è®¾ç½®è¾“å‡ºç›®å½•æ¥ä¿å­˜ .rrd æ–‡ä»¶"
        )

    # repo_id ç°åœ¨ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œä¸å†ä» dataset è·å–

    logger.info("æ­£åœ¨åŠ è½½æ•°æ®åŠ è½½å™¨ (DataLoader)...")
    dataloader = torch.utils.data.DataLoader(
        dataset,
        num_workers=num_workers,
        batch_size=batch_size,
    )

    logger.info(f"å¯åŠ¨ Rerun å¯è§†åŒ–ï¼Œæ¨¡å¼: {mode}")

    if mode not in ["local", "distant"]:
        raise ValueError(f"æ— æ•ˆçš„æ¨¡å¼: {mode}ã€‚å¿…é¡»æ˜¯ 'local' æˆ– 'distant'")

    spawn_local_viewer = mode == "local" and not save
    rr.init(f"{repo_id}/episode_{episode_index}", spawn=spawn_local_viewer)

    # æ‰‹åŠ¨è°ƒç”¨ Python åƒåœ¾å›æ”¶å™¨ï¼Œé¿å…åœ¨ num_workers > 0 æ—¶æŒ‚èµ·
    # TODO: å½“ rerun 0.16 ç‰ˆæœ¬å‘å¸ƒåç§»é™¤æ­¤ gc.collect
    gc.collect()

    if mode == "distant":
        logger.info(f"å¯åŠ¨ Web æœåŠ¡å™¨ï¼Œç«¯å£: {web_port}")
        logger.info(f"WebSocket ç«¯å£: {ws_port}")
        rr.serve_web_viewer(open_browser=False, web_port=web_port)

    logger.info("å¼€å§‹è®°å½•æ•°æ®åˆ° Rerun...")

    # å®šä¹‰å¸¸é‡
    ACTION = "action"
    DONE = "done"
    OBS_STATE = "observation.state"
    REWARD = "reward"

    for batch in tqdm.tqdm(dataloader, total=len(dataloader), desc="å¯è§†åŒ–è¿›åº¦"):
        # éå†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬
        for i in range(len(batch["index"])):
            frame_index = batch["frame_index"][i].item()
            timestamp = batch["timestamp"][i].item()

            rr.set_time("frame_index", sequence=frame_index)
            rr.set_time("timestamp", timestamp=timestamp)

            # æ˜¾ç¤ºæ¯ä¸ªç›¸æœºå›¾åƒï¼ˆå¸¦å‹ç¼©ï¼‰
            if hasattr(dataset.meta, 'camera_keys'):
                for key in dataset.meta.camera_keys:
                    if key in batch:
                        img_array = to_hwc_uint8_numpy(batch[key][i])
                        # å¦‚æœæŒ‡å®šäº†ç¼©æ”¾æ¯”ä¾‹ï¼Œç¼©å°å›¾åƒå°ºå¯¸
                        if scale_factor is not None and scale_factor < 1.0:
                            import cv2
                            h, w = img_array.shape[:2]
                            new_h, new_w = int(h * scale_factor), int(w * scale_factor)
                            img_array = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_AREA)
                        # ä½¿ç”¨ JPEG å‹ç¼©
                        rr.log(key, rr.Image(img_array).compress(jpeg_quality=jpeg_quality))
            else:
                # å°è¯•è‡ªåŠ¨æ£€æµ‹å›¾åƒé”®
                for key in batch.keys():
                    if 'image' in key.lower() or 'camera' in key.lower():
                        if isinstance(batch[key], torch.Tensor) and batch[key].dim() == 4:
                            img_array = to_hwc_uint8_numpy(batch[key][i])
                            # å¦‚æœæŒ‡å®šäº†ç¼©æ”¾æ¯”ä¾‹ï¼Œç¼©å°å›¾åƒå°ºå¯¸
                            if scale_factor is not None and scale_factor < 1.0:
                                import cv2
                                h, w = img_array.shape[:2]
                                new_h, new_w = int(h * scale_factor), int(w * scale_factor)
                                img_array = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_AREA)
                            # ä½¿ç”¨ JPEG å‹ç¼©
                            rr.log(key, rr.Image(img_array).compress(jpeg_quality=jpeg_quality))

            # æ˜¾ç¤ºåŠ¨ä½œç©ºé—´çš„æ¯ä¸ªç»´åº¦ï¼ˆä¾‹å¦‚ï¼šæ‰§è¡Œå™¨å‘½ä»¤ï¼‰
            if ACTION in batch:
                for dim_idx, val in enumerate(batch[ACTION][i]):
                    rr.log(f"{ACTION}/{dim_idx}", rr.Scalars(val.item()))

            # æ˜¾ç¤ºè§‚æµ‹çŠ¶æ€ç©ºé—´çš„æ¯ä¸ªç»´åº¦ï¼ˆä¾‹å¦‚ï¼šå…³èŠ‚ç©ºé—´ä¸­çš„æ™ºèƒ½ä½“ä½ç½®ï¼‰
            if OBS_STATE in batch:
                for dim_idx, val in enumerate(batch[OBS_STATE][i]):
                    rr.log(f"state/{dim_idx}", rr.Scalars(val.item()))

            # æ˜¾ç¤º done æ ‡å¿—
            if DONE in batch:
                rr.log(DONE, rr.Scalars(batch[DONE][i].item()))

            # æ˜¾ç¤ºå¥–åŠ±
            if REWARD in batch:
                rr.log(REWARD, rr.Scalars(batch[REWARD][i].item()))

            # æ˜¾ç¤ºæˆåŠŸæ ‡å¿—
            if "next.success" in batch:
                rr.log("next.success", rr.Scalars(batch["next.success"][i].item()))

    logger.info("æ•°æ®è®°å½•å®Œæˆï¼")

    if mode == "local" and save:
        # åœ¨æœ¬åœ°ä¿å­˜ .rrd æ–‡ä»¶
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        repo_id_str = repo_id.replace("/", "_")
        rrd_path = output_dir / f"{repo_id_str}_episode_{episode_index}.rrd"
        logger.info(f"ä¿å­˜ .rrd æ–‡ä»¶åˆ°: {rrd_path}")
        rr.save(rrd_path)
        logger.info(f"âœ“ æ–‡ä»¶å·²ä¿å­˜ï¼ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹:")
        logger.info(f"  rerun {rrd_path}")
        return rrd_path

    elif mode == "distant":
        logger.info("è¿œç¨‹æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ...")
        logger.info("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
        # é˜²æ­¢è¿›ç¨‹é€€å‡ºï¼Œå› ä¸ºå®ƒæ­£åœ¨æä¾› websocket è¿æ¥
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ° Ctrl-Cã€‚é€€å‡ºã€‚")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="LeRobot æ•°æ®é›†å¯è§†åŒ–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

  ä» HuggingFace åŠ è½½å¹¶å¯è§†åŒ–:
    python %(prog)s --repo-id lerobot/pusht --episode-index 0

  å¯è§†åŒ–æœ¬åœ°æ•°æ®é›†ï¼ˆæ¨èï¼‰:
    python %(prog)s --repo-id my_dataset --episode-index 0 --root D:/data/my_dataset --local

    æ³¨æ„: ä½¿ç”¨ --local å‚æ•°å¯ä»¥é¿å…è¿æ¥ HuggingFaceï¼Œé€‚ç”¨äºè‡ªå®šä¹‰æ•°æ®é›†

  ä¿å­˜ä¸º .rrd æ–‡ä»¶:
    python %(prog)s --repo-id my_dataset --episode-index 0 --root ./data --local --save 1 --output-dir ./output

  è¿œç¨‹æ¨¡å¼ï¼ˆæ•°æ®åœ¨æœåŠ¡å™¨ï¼‰:
    python %(prog)s --repo-id my_dataset --episode-index 0 --root ./data --local --mode distant --ws-port 9087
        """
    )

    parser.add_argument(
        "--repo-id",
        type=str,
        required=True,
        help="HuggingFace ä»“åº“ IDï¼ŒåŒ…å« LeRobotDataset æ•°æ®é›†ï¼ˆä¾‹å¦‚ï¼šlerobot/pushtï¼‰"
    )
    parser.add_argument(
        "--episode-index",
        type=int,
        required=True,
        help="è¦å¯è§†åŒ–çš„æƒ…èŠ‚ç´¢å¼•"
    )
    parser.add_argument(
        "--root",
        type=Path,
        default=None,
        help="æœ¬åœ°å­˜å‚¨çš„æ•°æ®é›†æ ¹ç›®å½•ï¼ˆä¾‹å¦‚ï¼š--root dataï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä» hugging face ç¼“å­˜æ–‡ä»¶å¤¹åŠ è½½æ•°æ®é›†ï¼Œæˆ–ä» hub ä¸‹è½½ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=None,
        help="å½“è®¾ç½® --save 1 æ—¶ï¼Œå†™å…¥ .rrd æ–‡ä»¶çš„ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=32,
        help="DataLoader åŠ è½½çš„æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼š32ï¼‰"
    )
    parser.add_argument(
        "--num-workers",
        type=int,
        default=4,
        help="DataLoader åŠ è½½æ•°æ®çš„è¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š4ï¼‰"
    )
    parser.add_argument(
        "--mode",
        type=str,
        default="local",
        choices=["local", "distant"],
        help="æŸ¥çœ‹æ¨¡å¼ï¼š'local' æˆ– 'distant'ã€‚'local' è¦æ±‚æ•°æ®åœ¨æœ¬åœ°æœºå™¨ä¸Šã€‚'distant' åœ¨å­˜å‚¨æ•°æ®çš„è¿œç¨‹æœºå™¨ä¸Šåˆ›å»ºæœåŠ¡å™¨ã€‚"
    )
    parser.add_argument(
        "--web-port",
        type=int,
        default=9090,
        help="å½“è®¾ç½® --mode distant æ—¶ï¼Œrerun.io çš„ Web ç«¯å£ï¼ˆé»˜è®¤ï¼š9090ï¼‰"
    )
    parser.add_argument(
        "--ws-port",
        type=int,
        default=9087,
        help="å½“è®¾ç½® --mode distant æ—¶ï¼Œrerun.io çš„ WebSocket ç«¯å£ï¼ˆé»˜è®¤ï¼š9087ï¼‰"
    )
    parser.add_argument(
        "--save",
        type=int,
        default=0,
        choices=[0, 1],
        help="åœ¨ --output-dir æä¾›çš„ç›®å½•ä¸­ä¿å­˜ .rrd æ–‡ä»¶ã€‚è¿™ä¹Ÿä¼šåœç”¨æŸ¥çœ‹å™¨çš„å¯åŠ¨ã€‚åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œ `rerun path/to/file.rrd` æ¥æŸ¥çœ‹æ•°æ®ã€‚"
    )
    parser.add_argument(
        "--tolerance-s",
        type=float,
        default=1e-4,
        help="ç”¨äºç¡®ä¿æ•°æ®æ—¶é—´æˆ³éµå®ˆæ•°æ®é›† fps å€¼çš„å®¹å·®ï¼ˆç§’ï¼‰ã€‚è¿™æ˜¯ä¼ é€’ç»™ LeRobotDataset æ„é€ å‡½æ•°çš„å‚æ•°ã€‚ï¼ˆé»˜è®¤ï¼š1e-4ï¼‰"
    )
    parser.add_argument(
        "--local",
        action="store_true",
        help="ä½¿ç”¨çº¯æœ¬åœ°æ¨¡å¼ï¼Œä¸å°è¯•è¿æ¥ HuggingFaceã€‚é€‚ç”¨äºæœ¬åœ°é‡‡é›†æˆ–è‡ªå®šä¹‰çš„æ•°æ®é›†ã€‚éœ€è¦æä¾› --root å‚æ•°ã€‚"
    )
    parser.add_argument(
        "--jpeg-quality",
        type=int,
        default=85,
        help="JPEG å‹ç¼©è´¨é‡ (1-100, é»˜è®¤85)ã€‚è¶Šä½æ–‡ä»¶è¶Šå°ï¼Œä½†ç”»è´¨è¶Šå·®ã€‚æ¨è: 70-90"
    )
    parser.add_argument(
        "--scale-factor",
        type=float,
        default=None,
        help="å›¾åƒç¼©æ”¾å› å­ (é»˜è®¤1.0=åŸå°ºå¯¸)ã€‚ä¾‹å¦‚: 0.5=åŠå°ºå¯¸, 0.25=å››åˆ†ä¹‹ä¸€å°ºå¯¸ã€‚å¯æ˜¾è‘—å‡å°æ–‡ä»¶å¤§å°ã€‚"
    )

    args = parser.parse_args()

    # éªŒè¯å‚æ•°
    if args.local and args.root is None:
        logger.error("ä½¿ç”¨ --local å‚æ•°æ—¶ï¼Œå¿…é¡»æä¾› --root å‚æ•°æŒ‡å®šæ•°æ®é›†è·¯å¾„")
        sys.exit(1)

    # æ£€æŸ¥ä¾èµ–
    check_dependencies()

    # ä½¿ç”¨æœ¬åœ°æ¨¡å¼ï¼Œé¿å…è¿æ¥ HuggingFace
    # æ³¨æ„ï¼šå¿…é¡»åœ¨å¯¼å…¥ LeRobotDataset ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
    if args.local:
        import os
        os.environ["HF_HUB_OFFLINE"] = "1"
        os.environ["TRANSFORMERS_OFFLINE"] = "1"
        os.environ["HF_DATASETS_OFFLINE"] = "1"
        logger.info("ğŸ”’ ä½¿ç”¨çº¯æœ¬åœ°æ¨¡å¼ï¼Œä¸ä¼šè¿æ¥ HuggingFace")

    # å¯¼å…¥ lerobot
    from lerobot.datasets.lerobot_dataset import LeRobotDataset

    # åŠ è½½æ•°æ®é›†
    logger.info(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {args.repo_id}")
    logger.info(f"æƒ…èŠ‚ç´¢å¼•: {args.episode_index}")

    if args.root:
        logger.info(f"æ•°æ®é›†æ ¹ç›®å½•: {args.root}")

    try:
        # æ„å»ºæ•°æ®é›†åŠ è½½å‚æ•°
        dataset_kwargs = {
            "repo_id": args.repo_id,
            "episodes": [args.episode_index],
            "tolerance_s": args.tolerance_s,
        }

        if args.root:
            dataset_kwargs["root"] = args.root

        dataset = LeRobotDataset(**dataset_kwargs)
        logger.info(f"âœ“ æ•°æ®é›†åŠ è½½æˆåŠŸï¼")
        logger.info(f"  æƒ…èŠ‚æ•°é‡: {dataset.num_episodes}")
        logger.info(f"  æ€»å¸§æ•°: {dataset.num_frames}")

        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        if hasattr(dataset.meta, 'info'):
            logger.info(f"  FPS: {dataset.meta.fps if hasattr(dataset.meta, 'fps') else 'N/A'}")

    except FileNotFoundError as e:
        logger.error(f"âŒ æ•°æ®é›†æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        if args.root:
            logger.error(f"è¯·æ£€æŸ¥ --root è·¯å¾„æ˜¯å¦æ­£ç¡®: {args.root}")
            logger.error("é¢„æœŸè·¯å¾„æ ¼å¼: --root D:/datasets/your_dataset")
            logger.error("æˆ–: --root /path/to/datasets/your_dataset")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")

        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if "huggingface.co" in str(e) or "Connection" in str(e):
            logger.error("\nğŸ’¡ è¿™çœ‹èµ·æ¥æ˜¯ç½‘ç»œè¿æ¥é—®é¢˜ã€‚")
            logger.error("å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯æœ¬åœ°æ•°æ®é›†ï¼Œè¯·æ·»åŠ  --local å‚æ•°:")
            logger.error(f"  python {sys.argv[0]} --repo-id {args.repo_id} --episode-index {args.episode_index} --root YOUR_DATA_PATH --local")
        else:
            logger.error("è¯·æ£€æŸ¥ä»¥ä¸‹å†…å®¹:")
            logger.error("  1. --repo-id æ˜¯å¦æ­£ç¡®")
            logger.error("  2. --episode-index æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…")
            logger.error("  3. --root è·¯å¾„æ˜¯å¦æ­£ç¡®")
            logger.error("  4. æ•°æ®é›†æ˜¯å¦å®Œæ•´ï¼ˆåŒ…å« meta/info.json ç­‰æ–‡ä»¶ï¼‰")
        sys.exit(1)

    # å‡†å¤‡å¯è§†åŒ–å‚æ•°
    viz_kwargs = {
        "batch_size": args.batch_size,
        "num_workers": args.num_workers,
        "mode": args.mode,
        "web_port": args.web_port,
        "ws_port": args.ws_port,
        "save": bool(args.save),
        "output_dir": args.output_dir,
        "jpeg_quality": args.jpeg_quality,
        "scale_factor": args.scale_factor,
    }

    # å¼€å§‹å¯è§†åŒ–
    try:
        result = visualize_dataset(dataset, args.repo_id, args.episode_index, **viz_kwargs)
        if result:
            logger.info(f"âœ“ å¯è§†åŒ–å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜åˆ°: {result}")
        elif args.mode == "local":
            logger.info("âœ“ å¯è§†åŒ–å®Œæˆï¼æŸ¥çœ‹å™¨åº”è¯¥å·²è‡ªåŠ¨æ‰“å¼€ã€‚")
    except Exception as e:
        logger.error(f"å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
